
R version 4.2.0 (2022-04-22) -- "Vigorous Calisthenics"
Copyright (C) 2022 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin17.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #######################################
> # WASH Benefits Bangladesh  
> # Hydrometeorological risk factors for diarrhea and enteropathogens
> 
> # process temperature data 
> # to calculate weekly sums with selected lags
> # for all days, not just the days with study data. 
> # this will be used in the figure showing risk 
> # factors over time. 
> #######################################
> 
> rm(list=ls())
> 
> ## configure directories, load libraries and base functions
> source(paste0(here::here(), "/0-config.R"))
here() starts at /Users/JGrembi/Dropbox/08_JadeCollaboration/wbb-weather-diarrhea-enteropathogens

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Loading required package: ggplot2

Attaching package: ‘reshape2’

The following object is masked from ‘package:tidyr’:

    smiths


Attaching package: ‘gridExtra’

The following object is masked from ‘package:dplyr’:

    combine

Welcome to the washb package
Version: 0.2.2
Created on 2018-11-07

This software was developed with funding from the
Bill & Melinda Gates Foundation (grant number OPPGD759).

The package's reference manual and vignette are also online:
https://ben-arnold.github.io/washb


Attaching package: ‘lubridate’

The following objects are masked from ‘package:base’:

    date, intersect, setdiff, union

Loading required package: nlme

Attaching package: ‘nlme’

The following object is masked from ‘package:dplyr’:

    collapse

This is mgcv 1.8-40. For overview type 'help("mgcv-package")'.
Loading required package: Matrix

Attaching package: ‘Matrix’

The following objects are masked from ‘package:tidyr’:

    expand, pack, unpack

Loading required package: lme4

Attaching package: ‘lme4’

The following object is masked from ‘package:nlme’:

    lmList

This is gamm4 0.2-6

This is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')
Loading required package: viridisLite
Loading required package: lattice

Attaching package: ‘caret’

The following object is masked from ‘package:purrr’:

    lift


Attaching package: ‘wrapr’

The following objects are masked from ‘package:Matrix’:

    pack, unpack

The following object is masked from ‘package:mgcv’:

    %.%

The following objects are masked from ‘package:tidyr’:

    pack, unpack

The following object is masked from ‘package:dplyr’:

    coalesce

── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
✔ tibble  3.2.1     ✔ forcats 0.5.2
✔ readr   2.1.3     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ lubridate::as.difftime() masks base::as.difftime()
✖ wrapr::coalesce()        masks dplyr::coalesce()
✖ nlme::collapse()         masks dplyr::collapse()
✖ gridExtra::combine()     masks dplyr::combine()
✖ lubridate::date()        masks base::date()
✖ Matrix::expand()         masks tidyr::expand()
✖ dplyr::filter()          masks stats::filter()
✖ tibble::has_name()       masks assertthat::has_name()
✖ lubridate::intersect()   masks base::intersect()
✖ dplyr::lag()             masks stats::lag()
✖ caret::lift()            masks purrr::lift()
✖ wrapr::pack()            masks Matrix::pack(), tidyr::pack()
✖ lubridate::setdiff()     masks base::setdiff()
✖ lubridate::union()       masks base::union()
✖ wrapr::unpack()          masks Matrix::unpack(), tidyr::unpack()
✖ tibble::view()           masks wrapr::view()

Attaching package: ‘kableExtra’

The following object is masked from ‘package:dplyr’:

    group_rows

Loading required package: foreach

Attaching package: ‘foreach’

The following objects are masked from ‘package:purrr’:

    accumulate, when

Loading required package: iterators
Loading required package: parallel
Loading required package: rngtools

Attaching package: ‘magrittr’

The following object is masked from ‘package:purrr’:

    set_names

The following object is masked from ‘package:tidyr’:

    extract


Attaching package: ‘cowplot’

The following object is masked from ‘package:lubridate’:

    stamp

> 
> # create date sequence for plot  ----------------------
> master_biweek <- readRDS(paste0(data_dir, "biweekly_plot_data/master_biweek_dates.RDS")) %>% filter(biweek_date <= as.Date("2016-01-21"))
> date_seq = as.list(master_biweek$biweek_date)
> 
> # read in temperature data ----------------------
> df_temp_original = readRDS(paste0(box_data_path, "daily_temperatures_fldas.RDS"))
> 
> df_temp = df_temp_original %>% 
+   mutate(lat = as.character(qgpslat),
+          long = as.character(qgpslong)) %>%
+   rename(Date = date)
> 
> # merge cluster ids into the temperature data ----------------------
> 
> ## Read in diarrhea data 
> df_diar = readRDS(paste0(data_dir, "biweekly_plot_data/d_diar_biweek.RDS"))
> 
> clusterids = df_diar %>%
+   filter(intervention == 0) %>% # Keep only clusters in the control arm
+   dplyr::select(clusterid, qgpslat, qgpslong, biweek) %>% 
+     mutate(
+       lat = as.character(qgpslat),
+       long = as.character(qgpslong)
+     ) %>% 
+   select(-qgpslat, -qgpslong) %>% 
+   distinct()
> 
> df_temp_merged = left_join(clusterids, df_temp, by = c("lat", "long"))
Warning message:
In left_join(clusterids, df_temp, by = c("lat", "long")) :
  Detected an unexpected many-to-many relationship between `x` and `y`.
ℹ Row 1 of `x` matches multiple rows in `y`.
ℹ Row 40 of `y` matches multiple rows in `x`.
ℹ If a many-to-many relationship is expected, set `relationship =
  "many-to-many"` to silence this warning.
> 
> ################################################################
> # Check that the number of unique coordinates that have #
> # been assigned to a cluster is equal to the number of unique 
> # coordinates in the merged df with a cluster
> ################################################################
> 
> # Check for equality 
> all_control = clusterids %>% select(lat, long) %>% distinct()
> all_merged = df_temp_merged %>% select(lat, long) %>% distinct()
> missing_coords = all_control %>% anti_join(all_merged,  by = c("long", "lat"))
> 
> assert_that(nrow(missing_coords) == 0, msg = glue::glue("{nrow(missing_coords)} coordinates were not matched with a cluster id"))
[1] TRUE
> 
> # Calculate lag time averages
> lag_times = data.frame(num_weeks_lag = c(0, 1, 2, 3),
+                        start = c(7, 14, 21, 28),
+                        end = c(1, 8, 15, 22))
> 
> # function to get mean temp within lag period ----------------------
> find_avg_7day_temp = function(data, date, lag_time){
+   
+   filtered_coords = data %>% filter(biweek == date) %>% select(long, lat) %>% distinct()
+   
+   while (nrow(filtered_coords) < 10) {
+     date = data %>% filter(biweek > date) %>% pull(biweek) %>% min()
+     filtered_coords = data %>% filter(biweek == date) %>% select(long, lat) %>% distinct()
+   }
+   
+   # subset data frame that defines lag period
+   selected_lag = lag_times %>% filter(num_weeks_lag == lag_time)
+   
+   # subset dates based on lag
+   date_filter = data %>% 
+     filter(Date >= date - selected_lag[["start"]], 
+            Date <= date - selected_lag[["end"]]) %>% 
+     inner_join(filtered_coords, by = c("long", "lat")) %>% 
+     select(-biweek) %>% 
+     distinct()
+   
+   # convert Kelvin to celsius
+   date_filter$temp = date_filter$temp - 273.15
+   
+   # get mean and CI
+   estimate = washb_mean(date_filter$temp, id=date_filter$clusterid, print = F) %>% 
+     as.data.frame()
+ 
+   # calculate mean in lag period in Celsius
+   return(data.frame(mean = estimate$Mean,
+                     lb = estimate$`Lower 95%CI`,
+                     ub = estimate$`Upper 95%CI`))
+ 
+ }
> 
> 
> for (n in lag_times$num_weeks_lag){
+   # run for each date 
+   mean_temp_df = lapply(date_seq, function(x) find_avg_7day_temp(data = df_temp_merged, 
+                                                                  date = x,
+                                                                  lag_time = n)) %>% bind_rows()
+   
+   mean_temp_savedata = data.frame(
+     date = master_biweek$biweek_date,
+     temp_weekavg_weeklag = mean_temp_df$mean,
+     temp_weekavg_weeklag_lb = mean_temp_df$lb,
+     temp_weekavg_weeklag_ub = mean_temp_df$ub
+   )
+   
+   colnames(mean_temp_savedata) = c("date", glue::glue("temp_weekavg_{n}weeklag"), 
+                                    glue::glue("temp_weekavg_{n}weeklag_lb"), glue::glue("temp_weekavg_{n}weeklag_ub"))
+   
+   saveRDS(mean_temp_savedata, file = paste0(data_dir, glue::glue("biweekly_plot_data/temp_mean_{n}wklag_time_for_plot.RDS")))
+ }

Attaching package: ‘zoo’

The following objects are masked from ‘package:base’:

    as.Date, as.Date.numeric


-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 343 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 343 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 343 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 343 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 1057 
-----------------------------------------

-----------------------------------------
Dropping 7 observations
due to missing values in the outcome
 Final sample size: 868 
-----------------------------------------

-----------------------------------------
Dropping 14 observations
due to missing values in the outcome
 Final sample size: 385 
-----------------------------------------

-----------------------------------------
Dropping 7 observations
due to missing values in the outcome
 Final sample size: 315 
-----------------------------------------

-----------------------------------------
Dropping 14 observations
due to missing values in the outcome
 Final sample size: 385 
-----------------------------------------

-----------------------------------------
Dropping 7 observations
due to missing values in the outcome
 Final sample size: 679 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 343 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 343 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 343 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 343 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 1057 
-----------------------------------------

-----------------------------------------
Dropping 7 observations
due to missing values in the outcome
 Final sample size: 868 
-----------------------------------------

-----------------------------------------
Dropping 14 observations
due to missing values in the outcome
 Final sample size: 385 
-----------------------------------------

-----------------------------------------
Dropping 7 observations
due to missing values in the outcome
 Final sample size: 315 
-----------------------------------------

-----------------------------------------
Dropping 14 observations
due to missing values in the outcome
 Final sample size: 385 
-----------------------------------------

-----------------------------------------
Dropping 7 observations
due to missing values in the outcome
 Final sample size: 679 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 343 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 343 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 343 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 343 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 1057 
-----------------------------------------

-----------------------------------------
Dropping 7 observations
due to missing values in the outcome
 Final sample size: 868 
-----------------------------------------

-----------------------------------------
Dropping 14 observations
due to missing values in the outcome
 Final sample size: 385 
-----------------------------------------

-----------------------------------------
Dropping 7 observations
due to missing values in the outcome
 Final sample size: 315 
-----------------------------------------

-----------------------------------------
Dropping 14 observations
due to missing values in the outcome
 Final sample size: 385 
-----------------------------------------

-----------------------------------------
Dropping 7 observations
due to missing values in the outcome
 Final sample size: 679 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 343 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 343 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 343 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 343 
-----------------------------------------

-----------------------------------------
Dropping 21 observations
due to missing values in the outcome
 Final sample size: 1057 
-----------------------------------------

-----------------------------------------
Dropping 7 observations
due to missing values in the outcome
 Final sample size: 868 
-----------------------------------------

-----------------------------------------
Dropping 14 observations
due to missing values in the outcome
 Final sample size: 385 
-----------------------------------------

-----------------------------------------
Dropping 7 observations
due to missing values in the outcome
 Final sample size: 315 
-----------------------------------------

-----------------------------------------
Dropping 14 observations
due to missing values in the outcome
 Final sample size: 385 
-----------------------------------------

-----------------------------------------
Dropping 7 observations
due to missing values in the outcome
 Final sample size: 679 
-----------------------------------------
> 
> 
> #--------------------------------------
> # Capture session info
> #--------------------------------------
> sessionInfo()
R version 4.2.0 (2022-04-22)
Platform: x86_64-apple-darwin17.0 (64-bit)
Running under: macOS Big Sur/Monterey 10.16

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] parallel  grid      stats     graphics  grDevices utils     datasets 
[8] methods   base     

other attached packages:
 [1] lmtest_0.9-40      zoo_1.8-11         sandwich_3.0-2     cowplot_1.1.1     
 [5] MetBrewer_0.2.0    RColorBrewer_1.1-3 rcartocolor_2.0.0  broom_1.0.5       
 [9] magrittr_2.0.3     doRNG_1.8.2        rngtools_1.5.2     doParallel_1.0.17 
[13] iterators_1.0.14   foreach_1.5.2      tictoc_1.1         rmarkdown_2.25    
[17] kableExtra_1.3.4   forcats_0.5.2      readr_2.1.3        tibble_3.2.1      
[21] tidyverse_1.3.2    pgirmess_2.0.0     wrapr_2.0.9        caret_6.0-93      
[25] lattice_0.20-45    viridis_0.6.4      viridisLite_0.4.2  purrr_1.0.2       
[29] DHARMa_0.4.6       gamm4_0.2-6        lme4_1.1-35.1      Matrix_1.6-4      
[33] mgcv_1.8-40        nlme_3.1-160       assertthat_0.2.1   boxr_0.3.6        
[37] ncdf4_1.19         stringr_1.5.1      lubridate_1.8.0    washb_0.2.2       
[41] gridExtra_2.3      reshape2_1.4.4     tidyr_1.3.0        ggcorrplot_0.1.4  
[45] ggplot2_3.4.4      dplyr_1.1.4        here_1.0.1        

loaded via a namespace (and not attached):
 [1] readxl_1.4.3         backports_1.4.1      systemfonts_1.0.4   
 [4] plyr_1.8.9           sp_1.5-0             splines_4.2.0       
 [7] listenv_0.8.0        digest_0.6.33        htmltools_0.5.7     
[10] fansi_1.0.6          googlesheets4_1.0.1  tzdb_0.3.0          
[13] recipes_1.0.2        globals_0.16.1       modelr_0.1.9        
[16] gower_1.0.0          svglite_2.1.0        hardhat_1.2.0       
[19] colorspace_2.1-0     rvest_1.0.3          haven_2.5.1         
[22] xfun_0.41            crayon_1.5.2         jsonlite_1.8.8      
[25] survival_3.4-0       glue_1.6.2           gtable_0.3.4        
[28] gargle_1.2.1         ipred_0.9-13         webshot_0.5.4       
[31] future.apply_1.9.1   scales_1.3.0         DBI_1.1.3           
[34] Rcpp_1.0.11          spData_2.2.0         units_0.8-0         
[37] spdep_1.2-7          proxy_0.4-27         stats4_4.2.0        
[40] lava_1.6.10          prodlim_2019.11.13   httr_1.4.7          
[43] wk_0.7.0             pkgconfig_2.0.3      nnet_7.3-18         
[46] dbplyr_2.2.1         deldir_1.0-6         utf8_1.2.4          
[49] tidyselect_1.2.0     rlang_1.1.2          munsell_0.5.0       
[52] cellranger_1.1.0     tools_4.2.0          cli_3.6.2           
[55] generics_0.1.3       evaluate_0.23        fastmap_1.1.1       
[58] ModelMetrics_1.2.2.2 knitr_1.45.8         fs_1.6.3            
[61] s2_1.1.0             future_1.28.0        xml2_1.3.3          
[64] compiler_4.2.0       rstudioapi_0.14      e1071_1.7-11        
[67] reprex_2.0.2         stringi_1.8.2        classInt_0.4-8      
[70] nloptr_2.0.3         vctrs_0.6.5          pillar_1.9.0        
[73] lifecycle_1.0.4      data.table_1.14.10   R6_2.5.1            
[76] KernSmooth_2.23-20   parallelly_1.32.1    codetools_0.2-18    
[79] boot_1.3-28          MASS_7.3-58.1        rprojroot_2.0.4     
[82] withr_2.5.2          hms_1.1.3            rpart_4.1.16        
[85] timeDate_4021.106    class_7.3-20         minqa_1.2.6         
[88] googledrive_2.0.0    sf_1.0-12            pROC_1.18.0         
> 
> 
> proc.time()
   user  system elapsed 
141.299  23.885 166.574 
